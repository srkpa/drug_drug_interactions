#!/usr/bin/env python

import os
import json
import sys
import traceback
import click
import numpy as np
from side_effects.expts_routines import run_experiment

TORCH = True
try:
    import torch
except ImportError:
    TORCH = False

PREFIX = '/opt/ml/'


@click.command()
@click.option('--config_file', '-p', default=os.path.join(PREFIX, 'input/config/hyperparameters.json'),
              help="Path to the config file (json) that contains the parameters for the experiment.")
@click.option('--input_path', '-i', default="s3://datasets-ressources/DDI/twosides-for-seed",
              help="Location of the input data files")
@click.option('--output_path', '-o', help="Location for saving the training results (model artifacts and output files).")
@click.option('--restore_path', '-r', help="Path for model restoration (resume training at last checkpoint).")
@click.option('--checkpoint_path', '-c', help="S3 path where to save the checkpoint of the model.")
def main(config_file, input_path, output_path, restore_path, checkpoint_path):
    print('Starting the training.')
    os.makedirs(output_path, exist_ok=True)
    try:
        # Read in any hyperparameters that the user passed with the training job
        # Depending on how you set the hyperparameters
        train_params = {}
        with open(config_file, 'r') as tc:
            train_params = json.load(tc)
        # the function below does all the data loading, run, validate and test_ddi the algo
        run_experiment(**train_params, output_path=output_path,
                       input_path=input_path, restore_path=restore_path, checkpoint_path=checkpoint_path)
        print("Launching with {}".format(train_params))

    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' +
              str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)


if __name__ == '__main__':
    np.random.seed(42)
    if TORCH:
        torch.manual_seed(42)
    # These are the paths where SageMaker mounts interesting things in your container.
    main()
    sys.exit(0)
